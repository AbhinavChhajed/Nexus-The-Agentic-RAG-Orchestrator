{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e82c5e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "import mimetypes\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import dotenv\n",
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "import requests\n",
    "import json\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing import Literal\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0252239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected argument 'temprature' provided to ChatGoogleGenerativeAI. Did you mean: 'temperature'?\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: UserWarning: WARNING! temprature is not default parameter.\n",
      "                temprature was transferred to model_kwargs.\n",
      "                Please confirm that temprature is what you intended.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temprature = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e89e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalLoader:\n",
    "    def __init__(self,llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def process_file(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Traffic Controller: Routes files to the correct reader.\n",
    "        \"\"\"\n",
    "        # 1. Get extension and mime type\n",
    "        _, ext = os.path.splitext(file_path)\n",
    "        ext = ext.lower()\n",
    "        mime_type, _ = mimetypes.guess_type(file_path)\n",
    "        \n",
    "        # 2. DEFINE CODE EXTENSIONS (Treat these as text)\n",
    "        code_extensions = {'.py', '.js', '.ts', '.html', '.css', '.java', '.cpp', '.c', '.h', '.sql', '.md', '.json', '.xml', '.yaml', '.yml', '.txt'}\n",
    "\n",
    "        if ext in code_extensions:\n",
    "            return self._process_code(file_path, ext)\n",
    "        \n",
    "        elif mime_type and \"pdf\" in mime_type:\n",
    "            return self._process_pdf(file_path)\n",
    "        \n",
    "        elif mime_type and \"csv\" in mime_type:\n",
    "            return self._process_csv(file_path)\n",
    "        \n",
    "        elif mime_type and \"image\" in mime_type:\n",
    "            return self._process_image(file_path)\n",
    "        \n",
    "        else:\n",
    "            return f\"Unsupported file type: {mime_type or ext}\"\n",
    "        \n",
    "    def _process_code(self, file_path, ext):\n",
    "        \"\"\"Reads code files and wraps them in markdown.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            # Wrap in markdown so LLM knows it's code\n",
    "            lang_map = {'.py': 'python', '.js': 'javascript', '.ts': 'typescript', '.html': 'html', '.sql': 'sql', '.css': 'css'}\n",
    "            language = lang_map.get(ext, '')\n",
    "            return f\"```{language}\\n{content}\\n```\"\n",
    "        except Exception as e:\n",
    "            return f\"Error reading code file: {e}\"\n",
    "        \n",
    "    def _process_txt(self,file_path):\n",
    "        with open(file_path,'r') as f:\n",
    "            return f.read()\n",
    "        \n",
    "    def _process_pdf(self,file_path):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pages = loader.load_and_split()\n",
    "        result = \"\"\n",
    "        for page in pages:\n",
    "            result += page.page_content + \"\\n\"\n",
    "        return result\n",
    "    \n",
    "    def _process_csv(self,file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df.to_markdown(index=False)\n",
    "    \n",
    "    def _process_image(self,file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                    \n",
    "                image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "                \n",
    "                Prompt = HumanMessage(content = [\n",
    "                    {\"type\":\"text\",\"text\":\"Describe the following image in detail.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}},\n",
    "                ])\n",
    "                response = self.llm.invoke([Prompt])\n",
    "                return response.content\n",
    "\n",
    "        except Exception as e:\n",
    "            return \"error processing image: \" + str(e)\n",
    "        \n",
    "\n",
    "universalloader = UniversalLoader(model)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edc96886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 weeks ago - Udaipur (Hindi: IPA: [ʊdəjpʊɾ], pronunciationⓘ) (ISO 15919: Udayapura) is a city in the north-western Indian state of Rajasthan , about 415 km (258 mi) south of the state capital Jaipur. It serves as the administrative headquarters of Udaipur district. It is the historic capital of the ... 1 week ago - Udaipur district is one of the 50 districts of Rajasthan state in western India . The historic city of Udaipur is the administrative headquarters of the district. The district is part of the Mewar region of Rajasthan. Before Udaipur district was established in independent India, it was a part ... August 31, 2025 - उदयपुर (Udaipur) भारत के राजस्थान राज्य के उदयपुर ज़िले में स्थित एक नगर है। यह राजस्थान का एक प्रमुख ... March 7, 2025 - Maharana Jagat Singh-I (1628-1652) further added more rooms to the Raaj-Mahal and further developed Jagmandir island palace and temples in the city. Over the centuries, four more water bodies were added to Pichola to its north, viz.-Amar Kund + Rang Sagar + Kumbhariya Talab + Swaroop Sagar (Kalaliya Shiv-Sagar). These additions resulted in diversion of Pichola's overflow from east to north through Swaroopsagar using Gumaniyawala that met Ayad River to east of present-day Zonal Railway Training Institute, near Panchavati. Fruitless attacks on Udaipur by Mughal Emperors Akbar (1576) and later on by Aurangzeb (1680) proved the location (terrain) advantage of this capital city which was defended by natural features rather than the man-made battlement! October 28, 2025 - Udaipur (Bengali pronunciation: [udɔe̯pur]), formerly known as Rangamati, is the third biggest urban area in the Indian state of Tripura . The city was the capital of the state during the reign of the Manikya dynasty.\n"
     ]
    }
   ],
   "source": [
    "search_tool = DuckDuckGoSearchRun()\n",
    "search_tool.name = \"search_tool\"\n",
    "search_tool.description = \"web search tool to find more information about a topic\"\n",
    "result = search_tool.invoke(\"where is udaipur?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96a8afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "vector_store = FAISS.from_texts([\"Nexus Initialized\"], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb6d3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_files(file_paths):\n",
    "    \"\"\"\n",
    "    Reads files -> Chunks them -> Saves to Vector DB (Locally)\n",
    "    \"\"\"\n",
    "    all_documents = []\n",
    "    \n",
    "    for path in file_paths:\n",
    "        print(f\"Loading: {path}...\")\n",
    "        \n",
    "        # Extract Text using your UniversalLoader\n",
    "        raw_content = universalloader.process_file(path)\n",
    "        \n",
    "        # Convert to Document\n",
    "        doc = Document(page_content=raw_content, metadata={\"source\": path})\n",
    "        all_documents.append(doc)\n",
    "        \n",
    "    # Split into chunks\n",
    "    splits = text_splitter.split_documents(all_documents)\n",
    "    \n",
    "    # Add to Vector Store\n",
    "    if splits:\n",
    "        vector_store.add_documents(splits)\n",
    "        print(f\"Successfully indexed {len(splits)} chunks locally!\")\n",
    "    else:\n",
    "        print(\"No content found to index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f308c2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: nexus_local_test.py...\n",
      "Successfully indexed 1 chunks locally!\n"
     ]
    }
   ],
   "source": [
    "with open(\"nexus_local_test.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "def secure_handshake():\n",
    "    '''Local encryption protocol for Nexus'''\n",
    "    return \"Handshake Accepted\"\n",
    "\"\"\")\n",
    "\n",
    "# Run the Indexer\n",
    "index_files([\"nexus_local_test.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24f0baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78715509",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search and retrieve information from internal documents, code, and policies.\n",
    "    Use this tool when the user asks about specific files or internal knowledge.\n",
    "    \"\"\"\n",
    "    pages = retriever.invoke(query)\n",
    "    result = \"\"\n",
    "    for page in pages:\n",
    "        result += page.page_content + \"\\n\\n\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ac38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_repl = PythonREPL()\n",
    "@tool\n",
    "def python_interpreter(code: str) -> str:\n",
    "    \"\"\"\n",
    "    A Python shell. Use this to execute python commands.\n",
    "    Input should be a valid python script.\n",
    "    Use this for math, data analysis, or processing text.\n",
    "    ALWAYS print(...) your final result so I can see it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = python_repl.run(code)\n",
    "        return f\"Executed:\\n{result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\" \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69fad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prototype Complete. Ready to migrate to Backend.\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: MessagesState) -> str:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM asks for a tool, go to \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, stop\n",
    "    return END\n",
    "\n",
    "# 1. The Approved Tools\n",
    "tools = [search_tool, retrieve_documents, python_interpreter]\n",
    "\n",
    "# 2. Bind Tools to Model\n",
    "model = model.bind_tools(tools)\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# 3. Define the Agent Logic\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 4. Build the Graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Prototype Complete. Ready to migrate to Backend.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
